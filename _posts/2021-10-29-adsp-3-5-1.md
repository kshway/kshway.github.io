---
title:  "[ADSP] 3과목 5장 정형데이터 마이닝 -1"
excerpt: "데이터 마이닝, 분류분석, 앙상블"

categories:
  - ADSP

tags:
  - license

toc: true
toc_sticky: true
use_math: true

date: 2021-10-29
last_modified_at: 2021-10-29
---

# 데이터마이닝의 개요
## 데이터 마이닝
### 개요
데이터마이닝은 대용량 데이터에서 의미있는 패턴을 파악하거나 예측하여 의사결정에 활용하는 방법

### 통계분석과 차이점
통계분석은 가설이나 가정에 따른 분석이나 검증을 하지만 데이터마이닝은 다양한 수리 알고리즘을 이용해 데이터베이스의 데이터로부터 의미있는 정보를 찾아내는 방법을 통칭한다

### 종류

|정보를 찾는 방법론에 따른 종류|분석대상, 활용목적, 표현방법에 따른 분류|
|---|---|
|- 인공지능<br>- 의사결정나무<br>- K-평균군집화<br>- 연관분석<br>- 회귀분석<br>- 로짓분석<br>- 최근접이웃|- 시각화분석<br>- 분류<br>- 군집화<br>- 포케스팅|

### 최근환경
- 데이터마이닝 도구가 다양하고 체계화되어 환경에 적합한 제품을 선택하여 활용 가능
- 알고리즘에 대한 깊은 이해가 없어도 분석에 큰 어려움이 없음
- 분석결과의 품질은 분석가의 경험과 역량에 따라 차이가 나기때문에 풍부한 경험을 가진 전문가에게 의뢰할 필요있음
- 국내에서 적용된 시기는 1990년대 중반
- 2000년대에 비즈니스 관점에서 데이터마이닝이 CRM의 중요한 요소로 부각
- 대중화를 위해 많은 시도가 있었으나, 통계학 전문가와 대기업 위주로 진행

## 데이터마이닝의 분석방법
|지도학습(Supervised Learning)|비지도학습(Unsupervised Learning)|
|---|---|
|- 의사결정나무<br>- 인공신경망<br>- 일반화 선형 모형<br>- 회귀분석<br>- 로지스틱회귀분석<br>- 사례기반추론<br>- 최근접 이웃법|- OLAP<br>- 연관성 규칙발견<br>- 군집분석<br>- SOM|

## 분석 목적에 따른 작업 유형과 기법
- 예측
    - 분류규칙
        - 가장 많이 사용되는 작업
        - 과거의 데이터로부터 고객특성을 찾아내어 분류모형을 만들어 이를 토대로 새로운 레코드의 결과값을 예측하는 것으로 목표 마케팅 및 고객 신용 평가 모형에 확용
        - 회귀분석, 판별분석, 신경망, 의사결정나무
- 설명
    - 연관규칙
        - 데이터 안에 존재하는 항목간의 종속관계를 찾아내는 작업
        - 제품이나 서비스의 교차판매, 매장진열, 첨부우편, 사기적발 등의 다양한 분야에 활용됨
        - 동시발생매트릭스
    - 연속규칙
        - 연관규칙에 시간관련 정보가 포함된 형태
        - 고객구매이력속성이 반드시 필요
        - 목표마케팅이나 일대일 마케팅에 활용
        - 동시발생매트릭스
    - 데이터군집화
        - 고객 레코드를 유사한 특성을 지닌 몇개의 소그룹으로 분할하는 작업
        - 작업이 특성이 분류규칙과 유사하나 분석대상 데이터에 결과값이 없으며, 판촉활동이나 이벤트 대상을 선정하는데 활용
        - K-means Clustering
## 데이터마이닝 추진단계
1. 목적설정
    - 데이터마이닝을 통해 무엇을 왜 하는지 명확한 목적을 설정
    - 전문가가 참여해 목적에 따라 사용할 모델과 필요한 데이터를 정의
2. 데이터 준비
    - 고객정보, 거래정보, 상품 마스터정보, 웹로그 데이터, 소셜 네트워크 데이터 등 다양한 데이터 활용
    - IT 부서와 사전에 협의하고 일정을 조율하여 데이터 접근 부하에 유의하여야 하며, 필요시 다른 서버에 저장하여 운영에 지장이 없도록 데이터를 준비
    - 데이터 정제를 통해 데이터의 품질을 보장하고, 필요시 데이터를 보강하여 충분한 양의 데이터를 확보
3. 가공
    - 모델링 목적에 따라 목적 변수 정의
    - 필요한 데이터를 데이터마이닝 소프트웨어에 적용할 수 있는 형식으로 가공
4. 기법 적용
    - 1단계에서 명확한 목적에 맞게 데이터마이닝 기법을 적용하여 정보를 추출
5. 검증
    - 데이터마이닝으로 추출된 정보를 검증
    - 테스트 데이터와 과거 데이터를 활용하여 최적의 모델 선정
    - 검증이 완료되면 IT부서와 협의해 상시 데이터 마이닝 결과를 업무에 적용하고 보고서를 작성하여 추가수익과 투자대비성과들으로 기대효과 전파

## 데이터 마이닝을 위한 데이터 분할
1. 구축용(training data, 50%)
    - 추정용, 훈련용 데이터라고도 불리며 데이터마이닝 모델을 만드는데 활용
2. 검정용(validation data, 30%)
    - 구축된 모형의 과대추정 또는 과소추정을 미세 조정을 하는데 활용
3. 시험용(test data, 20%)
    - 테스트 데이터나 과거 데이터를 활용하여 모델의 성능을 검증하는데 활용
4. 데이터의 양이 충분하지 않거나 입력 변수에 대한 설명이 충분한 경우
    - 홀드아웃방법: 주어진 데이터를 랜덤하게 두 개의 데이터로 구분하여 사용, 주로 학습용과 시험용로 분리하여 사용
    - 교차확인방법: 주어진 데이터를 k개의 하부집단으로 구분하여, k-1개의 집단을 학습용으로 나머지는 하부집단으로 검증용으로 설정하여 학습, k번 반복 측정한 결과를 평균낸 값을 최종값으로 사용, 주로 10-fold 교차분석 많이 사용

## 성과분석
### 오분류에 대한 추정치
1. 정분류율(Accuracy)  
    $Accuracy = \frac{TN + TP}{TN + TP + FN + FP}$

2. 오분류율(Error Rate)  
    $1 - Accuracy = \frac{FN + FP}{TN + TP + FN + FP}$

3. 특이도(Specificity)  
    $Specificity = \frac{TN}{TN + FP}$

4. 민감도(Sensitivity)  
    $Sensitivity = \frac{TP}{TP + FN}$

5. 정확도(Precision)  
    $Precision = \frac{TP}{TP + FP}$

6. 재현율(Recall): 민감도와 같음  
    $Recall = \frac{TP}{TP + FN}$

7. F1 Score  
    $F_1 = 2 × \frac{Precicion x×Recall}{Precision + Recall}$

### ROCR 패키지로 성과분석
#### ROC Curve
- ROC Curve란 가로축을 FPR(False Positive Rate=1-특이도)로 두고, 세로축을 TPR(True Positive Rate, 민감도)로 두어 시각화한 그래프
- 2진 분류에서 모형의 성능을 평가하기 위해 많이 사용되는 척도
- 그래프가 왼쪽 상단에 가깝게 그려질수록 올바르게 예측한 비율은 높고, 잘못 예측한 비율은 낮음
- ROC곡선 아래의 면적을 의미하는 AURCC 값이 크면 클수록(1에 가까울수록) 모형의 성능이 좋다고 평가
- TRP(True Positive Rate, 민감도): 1인 케이스에 대한 1로 예측한 비율
- FPR(False Positive Rate, 1-특이도): 0인 케이스에 대한 1로 잘못 예측한 비율
- AUROC를 이용한 정확도의 판단기준

|기준|구분|
|:---:|:---:|
|0.9~1.0|excellent|
|0.8~0.9|good|
|0.7~0.8|fair|
|0.6~0.7|poor|
|0.5~0.6|fail|

### 이익도표(Lift chart)
1. 이익도표의 개념
    - 이익도표는 분류모형의 성능을 평가하기 위한 척도
    - 분류된 관측치에 대해 얼마나 예측이 잘 이루어졌는지를 나타내기 위해 임의로 나눈 각 등급별로 반응검출율, 반응률, 리프트 등의 정보를 산출하여 나타내는 도표
    - 2000명의 고객중 381명이 상품을 구매한 경우에 대해 이익도표를 만드는 과정
        - 먼저 데이터셋의 각 관측치에 대한 예측확률을 내림차순으로 정렬
        - 데이터를 10개의 구간으로 나눈다음 각 구간의 반응율을 산출
        - 기본 향상도(baseline lift)에 비해 반응률이 몇 배나 높은지를 계산하는데 이것을 향상도라고 함
    - 이익도표의 각 등급은 예측 확률에 따라 매겨진 순위이기 때문에, 상위 등급에서는 더 높은 반응률을 보이는 것이 좋은 모형

# 분류분석
## 분류분석과 예측분석
### 분류분석 정의
- 데이터가 어떤 그룹에 속하는지 예측하는데 사용되는 기법
- 클러스터링과 유사하지만, 분류분석은 각 그룹이 정의되어있음
- 교사학습에 해당하는 예측기법

### 예측분석의 정의
- 시계열분석처럼 시간에 따른 값 두 개만을 이용해 앞으로의 매출 또는 온도 등을 예측하는 것
- 모델링을 하는 입력 데이터가 어떤 것인지에 따라 특성이 다름
- 여러개의 다양한 설명변수가 아닌, 한 개의 설명변수로 생각하면 됨

### 분류분석, 예측분석의 공통점과 차이점
- 공통점
    - 레코드의 특정 속성의 값을 미리 알아맞히는 점

- 차이점
    - 분류: 레코드의 범주형 속성의 값을 알아맞히는 것
    - 예측: 레코드의 연속형 속성의 값을 알아맞히는 것

### 분류, 예측의 예
- 분류
    - 학생들의 국어, 영어, 수학 점수를 통해 내신등급을 알아맞히는 것
    - 카드회사에서 회원들의 가입 정보를 통해 1년 후 신용등급을 알아맞히는 것
- 예측
    - 학생들의 여러 가지 정보를 입력하여 수능점수를 알아맞히는 것
    - 카드회사 회원들의 가입정보를 통해 연 매출액을 알아맞히는 것

### 분류 모델링
- 신용평가모형
- 사기방지모형
- 이탈모형
- 고객세분화

### 분류 기법
- 회귀분석, 로지스틱 회귀분석
- 의사결정나무
- 베이지안 분류
- 인공신경망
- 지지도벡터기계
- k 최근접 이웃
- 규칙기반의 분류와 사례기반추론

## 로지스틱 회귀분석
- 반응변수가 범주형인 경우에 적용되는 회귀분석모형
- 새로운 설명변수가 주어질 때 반응변수의 각 범주에 속할 확률이 얼마인지를 추정하여 추정 확률을 기준치에 따라 분류하는 목적으로 활용
- 모형의 적합을 통해 추정된 확률을 사후확률
- exp()의 의미는 나머지 변수가 주어질 때 x가 한단위 증가할때마다 성공의 오즈가 몇 배 증가하는지를 나타내는 것
- 선형회귀분석과 로지스틱 회귀분석의 비교

|목적|선형회귀분석|로지스틱회귀분석|
|:---:|:---:|:---:|
|종속변수|연속형변수|(0,1)|
|계수 추정법|최소제곱법|최대우도추정법|
|모형검정|F-검정, T-검정|카이제곱 검정|

- glm() 함수를 이용하여 로지스틱 회귀분석 실행
- R코드: glm(종속변수~독립변수1+...+독립변수k, family=binomial, data=데이터셋명)

## 의사결정나무
### 정의
- 분류함수를 의사결정 규칙으로 이뤄진 나무 모양으로 그리는 방법
- 연속적으로 발생하는 의사결정 문제를 시각화해 의사결정이 이뤄지는 시점과 성과를 한눈에 볼 수 있게 함
- 계산결과가 의사결정나무에 직접 나타나기 때문에 해석이 간편
- 주어진 입력값에 대하여 출력값을 예측하는 모형으로 분류나무와 회귀나무모형이 있음

### 예측력과 해석력
- 기대 집간의 사람들 중 가장 많은 반응을 보일 고객의 유치방안을 예측하고자 하는 경우에는 예측력에 치중
- 신용평가에서는 심사 결과 부적격 판정이 나온 경우 고객에게 부적격 이유를 설명해야하므로 해석력에 치중

### 의사결정나무의 활용
1. 세분화
    - 데이터를 비슷한 특성을 갖는 몇 개의 그룹으로 분할해 그룹별 특성을 발견하는 것
2. 분류
    - 여러 예측변수들에 근거해 관측개체의 목표변수 범주를 몇 개의 등급으로 분류하고자 하는 경우에 사용하는 기법
3. 예측
    - 자료에서 규칙을 찾아내고 이를 이용해 미래의 사건을 예측하고자 하는 경우
4. 차원축소 및 변수선택
    - 매우 많은 수의 예측변수 중에서 목표변수에 큰 영향을 미치는 변수들을 골라내고자 하는경우에 사용하는 기법
5. 교호작용효과의 파악
    - 여러 개의 예측변수들을 결합해 목표변수에 작용하는 규칙을 파악하고자 하는 경우
    - 범주의 병합 또는 연속형 변수의 이산화: 범주형 목표변수의 범주를 소수의 몇 개로 병합하거나 연속형 목표변수를 몇 개의 등급으로 이산화 하고자 하는 경우

### 의사결정나무의 특징
- 장점
    - 결과를 누구에게나 설명하기 용이
    - 모형을 만드는 방법이 계산적으로 복잡하지 않음
    - 대용량 데이터에서도 빠르게 만들 수 있음
    - 비정상 잡음 데이터에 대해서도 민감함이 없이 분류할 수 있음
    - 한 변수와 상관성이 높은 다른 불필요한 변수가 있어도 크게 영향을 받지 않음
    - 설명변수나 목표변수에 수치형변수와 범주형변수를 모두 사용 가능
    - 모형 분류 정확도 높음

- 단점
    - 새로운 자료에 대한 과대적합이 발생할 가능성 높음
    - 분류 경계선 부근의 자료값에 대해서 오차가 큼
    - 설명변수간의 중요도를 판단하기 쉽지않음

### 의사결정나무의 분석과정
1. 성장단계
    - 각 마디에서 적절한 최적의 분리규칙을 찾아서 나무를 성장시키는 과정으로 적절한 정지규칙을 만족하면 중단
2. 가지치기단계
    - 오차를 크게 할 위험이 높거나 부적절한 추론규칙을 가지고 있는 가지 또는 불필요한 가지를 제거하는 단계
3. 타당성 평가 단계
    - 이익도표, 위험도표 혹은 시험자료를 이용하여 의사결정나무를 평가하는 단계
4. 해석 및 예측단계
    - 구축된 나무모형을 해석하고 예측모형을 설정한 후 예측에 적용하는 단계

### 나무의 성장
#### 분리기준
- 이산형 목표변수

|기준값|분리기준|
|:---:|---|
|카이제곱 통계량 p값|P값이 가장 작은 예측변수와 그 때의 최적분리에 의해서 자식마디를 형성|
|지니 지수|지니 지수를 감소시켜주는 예측변수와 그 때의 최적분리에 의해서 자식마디를 선택|
|엔트로피 지수|엔트로피 지수가 가장 작은 예측 변수와 이 때의 최적분리에 의해 자식마디를 형성|

- 연속형 목표변수

|기준값|분리기준|
|:---:|---|
|분산분석에서 F통계량|P값이 가장 작은 예측변수와 그 때의 최적분리에 의해서 자식마디를 형성|
|분산의 감소량|분산의 감소량을 최대화하는 기준의 최적분리에 의해서 자식마디를 형성|

#### 정지규칙(stopping rule)
- 더 이상 분리가 일어나지 않고, 현재의 마디가 끝마디가 되도록 하는 규칙
- 정지기준: 의사결정나무의 깊이를 지정, 끝마디의 레코드 수의 최소 개수 지정

### 나무의 가지치기
- 너무 큰 나무모형은 자료를 과대적합하고 너무 작은 나무모형은 과소적합할 위험이 있음
- 나무의 크기를 모형의 복잡도로 볼 수있으며 최적의 나무 크기는 자료로 부터 추정하게 됨
- 일반적으로 사용되는 방법은 마디에 속하는 자료가 일정 수이하일 때 분할을 정지하고 비용-복잡도 가지치기를 이용하여 성장시킨 나무를 가지치기

## 불순도의 여러 가지 측도
1. 카이제곱 통계량
    - 카이제곱 통계량은 각 셀에 대한 ((실제도수-기대도수)의 제곱/기대도수)의 합
    - 기대도수 = 열의 합계 X 합의 합계 / 전체합계

2. 지니지수
    - 노드의 불순도를 나타내는 값
    - 지니지수의 값이 클수록 이질적이며 순수도가 낮다고 볼 수 있음

3. 엔트로피 지수
    - 열역학에서 쓰는 개념으로 무질서 정도에 대한 측도
    - 엔트로피 지수의 값이 클수록 순수도(PUrity)가 낮음
    - 엔트로피 지수가 가장 작은 예측 변수와 이때의 최적분리 규칙에 의해 자식마디 형성

## 의사결정나무 알고리즘
- CART(Classification and Regression Tree)
    - 앞에서 설명한 방식의 가장 많이 활용되는 의사결정나무 알고리즘으로 불순도의 측도로 출력변수가 범주형일 경우 지니지수를 이용, 연속형인 경우 분산을 이용한 이진분리를 사용
    - 개별 입력변수 뿐만 아니라 입력변수들의 선형결합들 중에서 최적의 분리를 찾을 수 있음
- C4.5와 C5.0 
    - CART와 다르게 각 마디에서 다지분리가 가능하며 범주형 입력변수에 대해서는 범주의 수만큼 분리가 일어남
    - 불순도의 측도로는 엔트로피지수를 사용
- CHAID
    - 가지치기를 하지 않고 적당한 크기에서 나무모형의 성장을 중지하며 입력변수가 반드시 범주형 변수이어야함
    - 불순도의 측도로는 카이제곱 통계량 사용

## 의사결정나무 예시

```r
idx <- sample(2, nrow(iris), replace = TRUE, prob=c(0.7,0.3))
train.data <- iris[idx==1,]
test.data<-iris[idx==2,]

iris.tree <- ctree(Species~., data= train.data)
plot(iris.tree)
```
![Rplot](https://user-images.githubusercontent.com/91586956/139404092-53e6aa4a-3e03-4e4e-a20f-1ae2fc725e42.png)

# 앙상블분석
## 앙상블
### 정의
- 주어진 자료로부터 여러 개의 예측모형들을 만든 후 예측모형들을 조합하여 하나의 최종 예측 모형을 만드는 방법
- 다중 모델 조합, 분류기 조합이 있음

### 학습방법의 불안정성
- 학습자료의 작은 변화에 의해 예측모형이 크게 변하는 경우, 그 학습방법은 불안정
- 가장 안정적인 방법으로는 1-nearest neighbor, 선형회귀모형이 존재
- 가장 불안정한 방법으로는 의사결정나무

### 앙상블 기법의 종류
#### 배깅
- 주어진 자료에서 여러 개의 붓스트랩 자료를 생성하고 각 붓스트랩 자료에 예측모형을 만든 후 결합하여 최종 예측모형을 만드는 방법
    - 붓스트랩은 주어진 자료에서 동일한 크기의 표본을 랜덤 복원추출로 뽑은 자료를 의미
    - 붓스트랩을 통해 100개의 샘플을 추출하더라도 전체 샘플의 36.8%는 샘플에 하넌도 선택되지 않을 수 있음
- 보팅은 여러 개의 모형으로부터 산출된 결과를 다수결에 의해서 최종 결과를 선정하는 과정
- 최적의 의사결정나무를 구축할 때 가장 어려운 부분이 가지치기지만 배깅에서는 가지치기를 하지 않고 최대로 성장한 의사결정나무들을 활용
- 훈련자료의 모집단의 분포를 모르기 때문에 실제 문제에서는 평균예측모형을 구할 수 없음
    - 배깅은 이러한 문제를 해결하기 위해 훈련자료를 모집단으로 생각하고 평균예측모형을 구하여 분산을 줄이고 예측력 향상

#### 부스팅
- 예측력이 약한 모형들을 결합하여 강한 예측모형을 만드는 방법
- 부스팅 방법 중 Freund&Schapire가 제안한 Adaboost는 이진분류 문제에서 랜덤 분류기보다 조금 더 좋은 분류기 n개에 각각 가중치를 설정하고 n개 분류기를 결합하여 최종 분류기를 만드는 방법을 제안(가중치 값은 1)
- 훈련오차를 빨리 그리고 쉽게 줄일 수 있음
- 배깅에 비해 많은 경우 예측오차가 향상되어 Adaboost의 성능이 배깅보다 뛰어난 경우 많음

#### 랜덤 포레스트
- 의사결정나무의 특징인 분산이 크다는 점을 고려하여 배깅과 부스팅보다 더 많은 무작위성을 주어 약한 학습기들을 생성한 후 이를 선형 결합하여 최종 학습기를 만드는 방법
- random input에 따른 forest of tree를 이용한 분류방법
- 랜덤한 forest에는 많은 트리들 생성
- 변수제거없이 실행되므로 정확도 측면에서 좋은 성과
- 이론적 설명이나 최종 결과에 대한 해석이 어렵다는 단점
- 예측력이 매우 높음. 특히 입력변수가 많은 경우, 배깅과 부스팅과 비슷하거나 좋은 예측력 보임
